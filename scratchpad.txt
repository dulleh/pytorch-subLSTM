(base) bash-4.2$ python run.py --verbose --timing --model=subLSTMCuda --cuda --batch-size=3 --seq-length=7 --nhid=2 --epochs=1 --training-size=7
cuda is available: True
cudnn enabled: True
Training subLSTMCuda model with parameters:
	number of layers: 1
	hidden units: 2
	max epochs: 1
	batch size: 3
	optimizer: rmsprop, lr=0.0001, l2=0
	using CUDA
training epoch 1
dE/dh0.01 *
-2.0290  2.7442
 -6.8647  9.2844
  5.5416 -7.4950
[ CUDAFloatType{3,2} ]
grad_cell 0  0
 0  0
 0  0
[ CUDAFloatType{3,2} ]
new_cell-0.0321  0.9393
-0.0242  0.8467
 0.0110  0.8795
[ CUDAFloatType{3,2} ]
input_gate 0.5361  0.2002
 0.5110  0.2517
 0.5107  0.2630
[ CUDAFloatType{3,2} ]
output_gate 0.2663  0.6520
 0.3032  0.6518
 0.3073  0.6554
[ CUDAFloatType{3,2} ]
candidate_cell 0.5946  0.6204
 0.5361  0.6485
 0.5282  0.6551
[ CUDAFloatType{3,2} ]
X-0.0038  0.1337  0.9442  0.0000
 0.1428  0.0621  0.4712  0.0000
 0.1907  0.0474  0.4006  0.0000
[ CUDAFloatType{3,4} ]
gate_weights.sizes()[3, 4, 2]
gate_weights(1,.,.) =
  0.1446 -1.3848
 -1.0133  0.6277
  0.3829  0.4913
 -0.3046  0.5761

(2,.,.) =
  0.0441 -1.0894
 -0.8320  0.6269
  0.1446  0.6122
  0.0256  0.2734

(3,.,.) =
  0.0427 -1.0304
 -0.8125  0.6429
  0.1131  0.6414
  0.0827  0.2280
[ CUDAFloatType{3,4,2} ]
weights.sizes()[8, 4]
weights 0.6010  0.5108  0.3214  0.6770
 0.6453  0.4694 -0.4958  0.2441
-0.2626  0.1918 -0.4936  0.5788
 0.6845  0.4401  0.1471 -0.4400
 0.0896 -0.4237  0.5956 -0.3823
 0.4720  0.2928 -0.1539 -0.2095
 0.2722 -0.1878 -0.5853  0.2427
 0.0263  0.2287  0.6134  0.0776
[ CUDAFloatType{8,4} ]
old_cell-0.2133  0.8109
-0.0973  0.7923
-0.0126  0.8755
[ CUDAFloatType{3,2} ]
dE/dh0.01 *
-0.4512 -0.0665
 -1.6096 -0.2127
  1.3099  0.1582
[ CUDAFloatType{3,2} ]
grad_cell0.01 *
-0.2152  0.3550
 -0.8689  1.1076
  0.7213 -0.8649
[ CUDAFloatType{3,2} ]
new_cell-0.2133  0.8109
-0.0973  0.7923
-0.0126  0.8755
[ CUDAFloatType{3,2} ]
input_gate 0.6736  0.3358
 0.4810  0.2520
 0.5142  0.2649
[ CUDAFloatType{3,2} ]
output_gate 0.4506  0.5586
 0.3329  0.6262
 0.3061  0.6585
[ CUDAFloatType{3,2} ]
candidate_cell 0.4187  0.6187
 0.5013  0.6402
 0.5288  0.6568
[ CUDAFloatType{3,2} ]
X 0.2686  0.0389  0.2838  1.0000
-0.0269  0.1281  0.3099  0.0000
 0.2056  0.0535  0.4066  0.0000
[ CUDAFloatType{3,4} ]
gate_weights.sizes()[3, 4, 2]
gate_weights(1,.,.) =
  0.7246 -0.6821
 -0.1981  0.2353
 -0.3281  0.4841
  0.4166  0.2341

(2,.,.) =
 -0.0761 -1.0879
 -0.6951  0.5161
  0.0054  0.5763
  0.0614  0.1851

(3,.,.) =
  0.0566 -1.0209
 -0.8183  0.6566
  0.1155  0.6493
  0.0821  0.2335
[ CUDAFloatType{3,4,2} ]
weights.sizes()[8, 4]
weights 0.6010  0.5108  0.3214  0.6770
 0.6453  0.4694 -0.4958  0.2441
-0.2626  0.1918 -0.4936  0.5788
 0.6845  0.4401  0.1471 -0.4400
 0.0896 -0.4237  0.5956 -0.3823
 0.4720  0.2928 -0.1539 -0.2095
 0.2722 -0.1878 -0.5853  0.2427
 0.0263  0.2287  0.6134  0.0776
[ CUDAFloatType{8,4} ]
old_cell 0.0691  0.9457
-0.2284  0.7400
-0.0524  0.8663
[ CUDAFloatType{3,2} ]
dE/dh0.001 *
 0.0255  0.8462
  0.5726  2.9131
 -0.3749 -2.4175
[ CUDAFloatType{3,2} ]
grad_cell0.001 *
-1.4540  1.0272
 -4.3766  3.0544
  3.6588 -2.5108
[ CUDAFloatType{3,2} ]
new_cell 0.0691  0.9457
-0.2284  0.7400
-0.0524  0.8663
[ CUDAFloatType{3,2} ]
input_gate 0.5624  0.2186
 0.6595  0.3487
 0.5259  0.2177
[ CUDAFloatType{3,2} ]
output_gate 0.2486  0.6814
 0.4701  0.5489
 0.2813  0.6505
[ CUDAFloatType{3,2} ]
candidate_cell 0.6121  0.6411
 0.3973  0.6213
 0.5710  0.6300
[ CUDAFloatType{3,2} ]
X 0.2517  0.0328  0.9569  0.0000
 0.2466  0.0339  0.1352  1.0000
 0.0327  0.1216  0.7675  0.0000
[ CUDAFloatType{3,4} ]
gate_weights.sizes()[3, 4, 2]
gate_weights(1,.,.) =
  0.2507 -1.2736
 -1.1060  0.7601
  0.4561  0.5803
 -0.2235  0.5676

(2,.,.) =
  0.6611 -0.6250
 -0.1199  0.1962
 -0.4165  0.4951
  0.4985  0.1412

(3,.,.) =
  0.1036 -1.2793
 -0.9379  0.6214
  0.2860  0.5321
 -0.1890  0.4659
[ CUDAFloatType{3,4,2} ]
weights.sizes()[8, 4]
weights 0.6010  0.5108  0.3214  0.6770
 0.6453  0.4694 -0.4958  0.2441
-0.2626  0.1918 -0.4936  0.5788
 0.6845  0.4401  0.1471 -0.4400
 0.0896 -0.4237  0.5956 -0.3823
 0.4720  0.2928 -0.1539 -0.2095
 0.2722 -0.1878 -0.5853  0.2427
 0.0263  0.2287  0.6134  0.0776
[ CUDAFloatType{8,4} ]
old_cell 0.0435  0.8198
 0.0543  0.8730
-0.2154  0.7389
[ CUDAFloatType{3,2} ]
dE/dh0.0001 *
-0.4261  0.8948
 -2.3992  2.4661
  1.2392 -1.4736
[ CUDAFloatType{3,2} ]
grad_cell0.001 *
-0.2842  0.5272
 -1.6059  1.2160
  0.7081 -1.2574
[ CUDAFloatType{3,2} ]
new_cell 0.0435  0.8198
 0.0543  0.8730
-0.2154  0.7389
[ CUDAFloatType{3,2} ]
input_gate 0.5397  0.2102
 0.5429  0.2324
 0.6847  0.2865
[ CUDAFloatType{3,2} ]
output_gate 0.2591  0.6614
 0.2670  0.6715
 0.4136  0.5551
[ CUDAFloatType{3,2} ]
candidate_cell 0.6027  0.6300
 0.5858  0.6453
 0.4691  0.5957
[ CUDAFloatType{3,2} ]
X 0.1382  0.0222  0.9007  0.0000
 0.2367  0.0178  0.7646  0.0000
 0.1880  0.0188  0.6246  1.0000
[ CUDAFloatType{3,4} ]
gate_weights.sizes()[3, 4, 2]
gate_weights(1,.,.) =
  0.1590 -1.3239
 -1.0505  0.6694
  0.4169  0.5323
 -0.2195  0.5277

(2,.,.) =
  0.1722 -1.1950
 -1.0099  0.7148
  0.3465  0.5984
 -0.1122  0.4457

(3,.,.) =
  0.7755 -0.9124
 -0.3490  0.2214
 -0.1239  0.3878
  0.1990  0.4364
[ CUDAFloatType{3,4,2} ]
weights.sizes()[8, 4]
weights 0.6010  0.5108  0.3214  0.6770
 0.6453  0.4694 -0.4958  0.2441
-0.2626  0.1918 -0.4936  0.5788
 0.6845  0.4401  0.1471 -0.4400
 0.0896 -0.4237  0.5956 -0.3823
 0.4720  0.2928 -0.1539 -0.2095
 0.2722 -0.1878 -0.5853  0.2427
 0.0263  0.2287  0.6134  0.0776
[ CUDAFloatType{8,4} ]
old_cell-0.0439  0.6358
 0.0244  0.7547
 0.0004  0.7074
[ CUDAFloatType{3,2} ]
dE/dh0.0001 *
 0.0447  0.3232
  0.5142  1.9308
 -0.0130 -0.9081
[ CUDAFloatType{3,2} ]
grad_cell0.0001 *
-0.6111  2.2049
 -3.8602  4.8316
  2.3070 -4.8347
[ CUDAFloatType{3,2} ]
new_cell-0.0439  0.6358
 0.0244  0.7547
 0.0004  0.7074
[ CUDAFloatType{3,2} ]
input_gate 0.4683  0.2921
 0.5340  0.2251
 0.5020  0.2672
[ CUDAFloatType{3,2} ]
output_gate 0.3508  0.6316
 0.2694  0.6624
 0.3121  0.6510
[ CUDAFloatType{3,2} ]
candidate_cell 0.4732  0.6612
 0.5855  0.6386
 0.5229  0.6560
[ CUDAFloatType{3,2} ]
X 0.1428  0.0150  0.0146  0.0000
 0.1792  0.0131  0.7681  0.0000
 0.2020  0.0079  0.3346  0.0000
[ CUDAFloatType{3,4} ]
gate_weights.sizes()[3, 4, 2]
gate_weights(1,.,.) =
 -0.1268 -0.8851
 -0.6156  0.5390
 -0.1074  0.6687
  0.3017 -0.0175

(2,.,.) =
  0.1364 -1.2361
 -0.9975  0.6740
  0.3455  0.5694
 -0.1291  0.4453

(3,.,.) =
  0.0081 -1.0089
 -0.7905  0.6236
  0.0915  0.6454
  0.1318  0.1788
[ CUDAFloatType{3,4,2} ]
weights.sizes()[8, 4]
weights 0.6010  0.5108  0.3214  0.6770
 0.6453  0.4694 -0.4958  0.2441
-0.2626  0.1918 -0.4936  0.5788
 0.6845  0.4401  0.1471 -0.4400
 0.0896 -0.4237  0.5956 -0.3823
 0.4720  0.2928 -0.1539 -0.2095
 0.2722 -0.1878 -0.5853  0.2427
 0.0263  0.2287  0.6134  0.0776
[ CUDAFloatType{8,4} ]
old_cell-0.0848  0.5382
-0.0580  0.5598
-0.0384  0.5851
[ CUDAFloatType{3,2} ]
dE/dh1e-05 *
-0.3176  0.4200
 -0.4848  2.2609
  0.2587 -2.1352
[ CUDAFloatType{3,2} ]
grad_cell0.0001 *
-0.1955  0.5779
 -0.7845  2.0511
  0.6534 -1.5432
[ CUDAFloatType{3,2} ]
new_cell-0.0848  0.5382
-0.0580  0.5598
-0.0384  0.5851
[ CUDAFloatType{3,2} ]
input_gate 0.4677  0.2495
 0.4881  0.2216
 0.5055  0.2128
[ CUDAFloatType{3,2} ]
output_gate 0.3360  0.6164
 0.3063  0.6233
 0.2884  0.6343
[ CUDAFloatType{3,2} ]
candidate_cell 0.5007  0.6365
 0.5428  0.6240
 0.5664  0.6226
[ CUDAFloatType{3,2} ]
X-0.0382  0.0663  0.2633  0.0000
-0.0594  0.0693  0.5520  0.0000
-0.0192  0.0636  0.7026  0.0000
[ CUDAFloatType{3,4} ]
gate_weights.sizes()[3, 4, 2]
gate_weights(1,.,.) =
 -0.1294 -1.1011
 -0.6810  0.4743
  0.0028  0.5601
  0.0972  0.1421

(2,.,.) =
 -0.0478 -1.2565
 -0.8174  0.5036
  0.1716  0.5065
 -0.0781  0.3193

(3,.,.) =
  0.0218 -1.3079
 -0.9034  0.5507
  0.2673  0.5006
 -0.1542  0.4115
[ CUDAFloatType{3,4,2} ]
weights.sizes()[8, 4]
weights 0.6010  0.5108  0.3214  0.6770
 0.6453  0.4694 -0.4958  0.2441
-0.2626  0.1918 -0.4936  0.5788
 0.6845  0.4401  0.1471 -0.4400
 0.0896 -0.4237  0.5956 -0.3823
 0.4720  0.2928 -0.1539 -0.2095
 0.2722 -0.1878 -0.5853  0.2427
 0.0263  0.2287  0.6134  0.0776
[ CUDAFloatType{8,4} ]
old_cell-0.2246  0.2825
-0.2346  0.2718
-0.2153  0.2915
[ CUDAFloatType{3,2} ]
dE/dh1e-06 *
 0.3951  2.0266
  1.8396  6.8491
 -1.3212 -5.3516
[ CUDAFloatType{3,2} ]
grad_cell1e-05 *
-0.5790  1.7093
 -1.8694  7.1828
  1.4216 -5.8773
[ CUDAFloatType{3,2} ]
new_cell-0.2246  0.2825
-0.2346  0.2718
-0.2153  0.2915
[ CUDAFloatType{3,2} ]
input_gate 0.6228  0.3080
 0.6113  0.3243
 0.6330  0.2939
[ CUDAFloatType{3,2} ]
output_gate 0.4822  0.5038
 0.5010  0.4982
 0.4656  0.5088
[ CUDAFloatType{3,2} ]
candidate_cell 0.3982  0.5905
 0.3767  0.5961
 0.4177  0.5854
[ CUDAFloatType{3,2} ]
X 0.0000  0.0000  0.1542  1.0000
 0.0000  0.0000  0.0023  1.0000
 0.0000  0.0000  0.2896  1.0000
[ CUDAFloatType{3,4} ]
gate_weights.sizes()[3, 4, 2]
gate_weights(1,.,.) =
  0.5017 -0.8094
 -0.0710  0.0153
 -0.4130  0.3659
  0.4267  0.1386

(2,.,.) =
  0.4528 -0.7341
  0.0039 -0.0071
 -0.5034  0.3893
  0.5156  0.0454

(3,.,.) =
  0.5452 -0.8765
 -0.1379  0.0352
 -0.3323  0.3451
  0.3474  0.2217
[ CUDAFloatType{3,4,2} ]
weights.sizes()[8, 4]
weights 0.6010  0.5108  0.3214  0.6770
 0.6453  0.4694 -0.4958  0.2441
-0.2626  0.1918 -0.4936  0.5788
 0.6845  0.4401  0.1471 -0.4400
 0.0896 -0.4237  0.5956 -0.3823
 0.4720  0.2928 -0.1539 -0.2095
 0.2722 -0.1878 -0.5853  0.2427
 0.0263  0.2287  0.6134  0.0776
[ CUDAFloatType{8,4} ]
old_cell 0  0
 0  0
 0  0
[ CUDAFloatType{3,2} ]
weights.grad:
tensor([[-1.2070e-04,  4.5008e-04,  1.9993e-03,  1.0211e-03],
        [-1.2592e-05, -2.9037e-04, -1.4734e-03, -7.6706e-04],
        [-5.9108e-04,  1.2290e-03,  6.1968e-03,  9.4415e-04],
        [-1.9085e-05, -1.2529e-03, -8.8855e-03, -5.2188e-04],
        [ 1.0127e-04, -4.4851e-04, -1.9670e-03, -1.1023e-03],
        [ 1.9397e-05,  3.8178e-04,  2.0509e-03,  7.8026e-04],
        [-5.7299e-06,  1.0336e-04,  4.5438e-04, -7.2841e-05],
        [-4.5990e-05,  2.9184e-04,  1.5033e-03,  7.8825e-04]], device='cuda:0')
bias.grad
tensor([ 0.0035, -0.0025,  0.0085, -0.0105, -0.0035,  0.0033,  0.0009,  0.0023],
       device='cuda:0')
../torch/csrc/utils/python_arg_parser.cpp:698: UserWarning: This overload of addcmul_ is deprecated:
	addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
	addcmul_(Tensor tensor1, Tensor tensor2, Number value)
run.py:288: RuntimeWarning: invalid value encountered in double_scalars
  np.sum(epoch_trace) / len(epoch_trace),
epoch 1 finished
	time for this epoch 17.50464677810669
	training_loss =   nan
	validation_loss = 0.2498
total time to train 17.50464677810669
Training ended:
	test loss 0.3352















(base) bash-4.2$ python run.py --timing --verbose --model=subLSTM --cuda --batch-size=4 --seq-length=10 --nhid=5 --epochs=1 --training-size=400
cuda is available: True
cudnn enabled: True
Training subLSTM model with parameters:
	number of layers: 1
	hidden units: 5
	max epochs: 1
	batch size: 4
	optimizer: rmsprop, lr=0.0001, l2=0
	using CUDA
training epoch 1
weights.grad:
tensor([[-1.3028e-02, -7.8852e-03,  1.3004e-02, -2.5968e-02,  3.7322e-03,
          4.7623e-02,  3.9602e-02],
        [-4.7613e-03, -3.1697e-03,  6.0573e-03, -1.1180e-02,  2.8693e-03,
          1.8737e-02,  2.0047e-02],
        [ 3.8093e-03,  2.1536e-03, -2.8880e-03,  6.3758e-03, -2.0764e-04,
         -1.2516e-02, -1.0601e-02],
        [-2.5939e-03, -1.7664e-03,  3.7268e-03, -6.6544e-03,  1.9588e-03,
          1.1184e-02,  1.1541e-02],
        [-6.6789e-03, -4.2367e-03,  7.9347e-03, -1.4993e-02,  3.1947e-03,
          2.6609e-02,  2.3472e-02],
        [-1.5159e-02, -1.1627e-02,  2.8361e-02, -4.7514e-02,  1.8129e-02,
          7.2286e-02,  7.6568e-02],
        [-1.2348e-02, -9.5126e-03,  2.3894e-02, -3.9774e-02,  1.5350e-02,
          5.9854e-02,  5.9304e-02],
        [ 8.6263e-03,  4.9958e-03, -6.7998e-03,  1.4719e-02, -9.5783e-04,
         -2.8730e-02, -2.8266e-02],
        [-5.9387e-03, -4.5894e-03,  1.1716e-02, -1.9390e-02,  7.6346e-03,
          2.8551e-02,  2.8762e-02],
        [-1.0345e-02, -8.2995e-03,  2.2703e-02, -3.6866e-02,  1.5279e-02,
          5.2677e-02,  4.8649e-02],
        [ 1.1738e-02,  7.1682e-03, -1.1648e-02,  2.3315e-02, -3.4582e-03,
         -4.3153e-02, -3.9543e-02],
        [ 5.5444e-03,  3.6957e-03, -7.3006e-03,  1.3337e-02, -3.5234e-03,
         -2.2357e-02, -2.2561e-02],
        [-3.7343e-03, -2.1178e-03,  2.8396e-03, -6.2623e-03,  2.1627e-04,
          1.2442e-02,  1.0595e-02],
        [ 2.3233e-03,  1.5852e-03, -3.3648e-03,  5.9958e-03, -1.7780e-03,
         -1.0181e-02, -1.0451e-02],
        [ 7.1521e-03,  4.5384e-03, -8.3249e-03,  1.5839e-02, -3.3243e-03,
         -2.7953e-02, -2.6430e-02],
        [-4.7941e-03, -2.7303e-03,  3.9690e-03, -8.4650e-03,  6.7630e-04,
          1.5647e-02,  1.4706e-02],
        [-1.3615e-03, -8.5835e-04,  1.5502e-03, -2.9596e-03,  6.2460e-04,
          4.9161e-03,  5.0240e-03],
        [ 1.5099e-04,  9.3409e-05, -9.7591e-05,  2.2753e-04, -1.4062e-06,
         -4.8980e-04, -4.8344e-04],
        [-9.4083e-04, -6.5661e-04,  1.3942e-03, -2.4611e-03,  7.5937e-04,
          3.8962e-03,  4.0381e-03],
        [ 4.1811e-04,  3.6089e-04, -8.1696e-04,  1.3558e-03, -5.4327e-04,
         -2.3450e-03, -2.4152e-03]], device='cuda:0')
bias.grad
tensor([ 0.1816,  0.0722, -0.0478,  0.0416,  0.0996,  0.2786,  0.2322, -0.1084,
         0.1125,  0.2096, -0.1628, -0.0855,  0.0469, -0.0374, -0.1055,  0.0612,
         0.0196, -0.0018,  0.0153, -0.0079], device='cuda:0')
../torch/csrc/utils/python_arg_parser.cpp:698: UserWarning: This overload of addcmul_ is deprecated:
	addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
	addcmul_(Tensor tensor1, Tensor tensor2, Number value)
	[batches    10 /    80] loss: 0.69506
	[batches    20 /    80] loss: 0.56578
	[batches    30 /    80] loss: 0.47163
	[batches    40 /    80] loss: 0.40916
	[batches    50 /    80] loss: 0.36570
	[batches    60 /    80] loss: 0.33462
	[batches    70 /    80] loss: 0.31301
	[batches    80 /    80] loss: 0.29913
epoch 1 finished
	time for this epoch 3.711806058883667
	training_loss = 0.4318
	validation_loss = 0.1984
total time to train 3.711806058883667
Training ended:
	test loss 0.2469





















































(base) bash-4.2$ python run.py --timing --verbose --model=subLSTMCuda --cuda --batch-size=4 --seq-length=10 --nhid=5 --epochs=1 --training-size=400
cuda is available: True
cudnn enabled: True
Training subLSTMCuda model with parameters:
	number of layers: 1
	hidden units: 5
	max epochs: 1
	batch size: 4
	optimizer: rmsprop, lr=0.0001, l2=0
	using CUDA
training epoch 1
weights.grad:
tensor([[-7.3554e-03, -4.8021e-03,  9.1275e-03, -1.6932e-02,  4.1361e-03,
          2.9031e-02,  2.9447e-02],
        [-2.9854e-03, -2.2245e-03,  5.0034e-03, -8.5954e-03,  3.0462e-03,
          1.3313e-02,  1.5021e-02],
        [ 2.4324e-03,  1.4162e-03, -1.8736e-03,  4.0773e-03, -2.7589e-04,
         -8.1397e-03, -9.0273e-03],
        [-1.7649e-03, -1.3275e-03,  3.2503e-03, -5.4614e-03,  2.0492e-03,
          8.4531e-03,  8.7092e-03],
        [-3.5559e-03, -2.5452e-03,  5.8879e-03, -1.0144e-02,  3.4243e-03,
          1.5912e-02,  1.5564e-02],
        [-1.4969e-02, -1.1525e-02,  2.8222e-02, -4.7202e-02,  1.8146e-02,
          7.1805e-02,  7.6468e-02],
        [-1.1587e-02, -9.1117e-03,  2.3351e-02, -3.8525e-02,  1.5428e-02,
          5.7510e-02,  5.8886e-02],
        [ 7.2370e-03,  4.2497e-03, -5.7617e-03,  1.2376e-02, -1.0542e-03,
         -2.4214e-02, -2.7569e-02],
        [-5.8892e-03, -4.5641e-03,  1.1679e-02, -1.9308e-02,  7.6371e-03,
          2.8408e-02,  2.8722e-02],
        [-9.8797e-03, -8.0508e-03,  2.2367e-02, -3.6098e-02,  1.5324e-02,
          5.1263e-02,  4.8366e-02],
        [ 6.8258e-03,  4.4954e-03, -8.3276e-03,  1.5539e-02, -3.7980e-03,
         -2.7062e-02, -2.9487e-02],
        [ 3.4742e-03,  2.5875e-03, -6.0536e-03,  1.0300e-02, -3.7222e-03,
         -1.5931e-02, -1.6970e-02],
        [-2.3924e-03, -1.3955e-03,  1.8493e-03, -4.0202e-03,  2.7853e-04,
          8.1104e-03,  9.0201e-03],
        [ 1.5784e-03,  1.1894e-03, -2.9360e-03,  4.9228e-03, -1.8584e-03,
         -7.6923e-03, -7.8762e-03],
        [ 3.8496e-03,  2.7605e-03, -6.1919e-03,  1.0750e-02, -3.5784e-03,
         -1.6876e-02, -1.7496e-02],
        [-2.6370e-03, -1.6416e-03,  2.6730e-03, -5.2779e-03,  9.5319e-04,
          9.1757e-03,  1.0481e-02],
        [-7.6759e-04, -5.5355e-04,  1.2098e-03, -2.1084e-03,  7.0139e-04,
          3.1554e-03,  3.4725e-03],
        [ 9.9290e-05,  6.1257e-05, -6.1887e-05,  1.4423e-04, -3.3746e-06,
         -3.0557e-04, -4.0264e-04],
        [-6.8265e-04, -5.1248e-04,  1.2404e-03, -2.0877e-03,  7.7851e-04,
          3.0782e-03,  3.2283e-03],
        [ 3.6314e-04,  2.9610e-04, -7.3292e-04,  1.2099e-03, -4.9228e-04,
         -1.9709e-03, -2.1869e-03]], device='cuda:0')
bias.grad
tensor([ 0.0550,  0.0258, -0.0150,  0.0161,  0.0307,  0.1381,  0.1111, -0.0450,
         0.0559,  0.1017, -0.0505, -0.0307,  0.0147, -0.0145, -0.0327,  0.0180,
         0.0064, -0.0006,  0.0062, -0.0035], device='cuda:0')
../torch/csrc/utils/python_arg_parser.cpp:698: UserWarning: This overload of addcmul_ is deprecated:
	addcmul_(Number value, Tensor tensor1, Tensor tensor2)
Consider using one of the following signatures instead:
	addcmul_(Tensor tensor1, Tensor tensor2, Number value)
	[batches    10 /    80] loss: 0.70262
	[batches    20 /    80] loss: 0.59005
	[batches    30 /    80] loss: 0.50532
	[batches    40 /    80] loss: 0.44769
	[batches    50 /    80] loss: 0.40644
	[batches    60 /    80] loss: 0.37465
	[batches    70 /    80] loss: 0.34901
	[batches    80 /    80] loss: 0.32813
epoch 1 finished
	time for this epoch 28.722397565841675
	training_loss = 0.4630
	validation_loss = 0.2589
total time to train 28.722397565841675
Training ended:
	test loss 0.3208
